{"cells":[{"cell_type":"code","source":["%fs ls FileStore/tables/tfidfdocs"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/tfidfdocs/austen_emma-f6ffd.txt</td><td>austen_emma-f6ffd.txt</td><td>903894</td></tr></tbody></table></div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["Goal is to create the TFIDF data - (term, docID, tfidf)\n\nSteps\n* Read the file and turn it into a stream of the form (term, docid)\n* For each term/docID pair, compute frequency (term, docid, count)\n* For each document, compute term count (docid, numTerms)\n* Join those two on docid, and divide to get (term, docid, tfidf)"],"metadata":{}},{"cell_type":"code","source":["# Reminder of what we are doing to words to make them terms\ndef termify(word):\n  return ''.join([c for c in word.lower() if 97 <= ord(c) <= 122])\n\n# Read the file and parse into words\n# Flatten the stream\n# Convert to terms\n# Remove 0-length terms\n# Add the filename -- our base stream is (term, docid)\n# Do this for two files and union them together\n\nemma = 'austen_emma-f6ffd'\nblake = 'blake_poems-9ea23'\n\ndef pathFor(filename):\n  return f\"/FileStore/tables/{filename}.txt\"\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["emma = process_file('austen_emma-f6ffd')\nblake = process_file('blake_poems-9ea23')\nall_records = emma.union(blake)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["docs = emma.union(blake)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Term frequency - (term, docID, count)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Doc length - (docID, num_terms)\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Join term frequency and doc length\nj = doc_length.keyBy(lambda p: p[0]).join(term_count.keyBy(lambda p: p[1]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# This just does a lot of destructuring of the joined streams\ndef compute_tf(p):\n  term = p[1][1][0]\n  docid = p[1][1][1]\n  termFreq = p[1][1][2]\n  termsPerDoc = p[1][0][1]\n  return (term, docid, float(termFreq)/float(termsPerDoc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Finished TF stream (term, docID, tf)\n  "],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"TFIDF","notebookId":3986014020452589},"nbformat":4,"nbformat_minor":0}
