{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import avro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avro Demo\n",
    "\n",
    "Situation so far:\n",
    "\n",
    "* Process streams of records using MapReduce (or MapReduce streaming)\n",
    "\n",
    "* Input data is from either delimited text files or \"free text\" files in HDFS\n",
    "  * Most data sets have a lot of structure -- they look more like rows in DB tables than like a flat sequence of fields\n",
    "\n",
    "*  What is Structure / Schema Information?\n",
    "  *  Fields have a type, types require validation\n",
    "  *  Fields are optional or mandatory\n",
    "  *  Aggregate fields:  arrays and records\n",
    "  \n",
    "* Fundamental operation performed by all mappers\n",
    "  * Read the record\n",
    "  * Parse into field on delimiter\n",
    "  * Validate fields (data type, mandatory fields present)\n",
    "  * Access fields to do calculation\n",
    "\n",
    "* Limitations due to flat records\n",
    "  * Fields are defined (only) by position\n",
    "    * Not natural / readable, so error prone\n",
    "  * Code to do record parsing must be repeated every place the record is used\n",
    "    * Having the same code in multiple places is never good software engineering\n",
    "    \n",
    "  * Changes to the schema will tend to break code (everywhere)\n",
    "    * Change field delimiter\n",
    "    * Change field order\n",
    "    * Add new fields\n",
    "    * Change data type\n",
    "    * Delete unneeded fields\n",
    "  \n",
    "Ideally:\n",
    "* The data schema lives with the data or is centrally defined, not redundantly defined with the process code\n",
    "* Processors can use an \"object-like\" representation for their code\n",
    "  * More readable, not dependent on actual format of record\n",
    "* Processors react \"appropriately\" in case the schema changes\n",
    "  * No code change required in case of non-breaking change\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data Set\n",
    "\n",
    "Embellished version of the City table\n",
    "\n",
    "Fields (in order):\n",
    "\n",
    "1.  id\n",
    "1.  name\n",
    "1.  country_code\n",
    "1.  district\n",
    "1.  up to three neighborhoods\n",
    "1.  mayor name\n",
    "1.  year mayor elected\n",
    "\n",
    "Schema requirements:\n",
    "\n",
    "* id is required and must be long\n",
    "* name is required and must be non-empty\n",
    "* country_code is required and must be a known country code\n",
    "* district is optional\n",
    "* up to three neighborhoods, all optional\n",
    "* mayor name is required but date elected is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = [\"USA\", \"NLD\", \"AFG\"]\n",
    "\n",
    "def read_cities():\n",
    "    cities = []\n",
    "    with open(\"city.txt\") as cityfile:\n",
    "        for line in cityfile:\n",
    "            cities.append(read_city(line))\n",
    "    return cities\n",
    "        \n",
    "def read_city(line):\n",
    "    id, name, country_code, \\\n",
    "        district, population, \\\n",
    "        n1, n2, n3, \\\n",
    "        mayor_name, year_elected = line.strip().split(\",\")\n",
    "         \n",
    "    # Check mandatory fields\n",
    "    if (not id) or (not name) or (not mayor_name):\n",
    "            raise Exception(\"Missing a field\")\n",
    "    # Check valid country code   \n",
    "    if country_code not in country_codes:\n",
    "        raise Exception(f\"Bad country code {country_code}\")\n",
    "    # Parse and convert integer fields\n",
    "    id = int(id)\n",
    "    population = int(population)\n",
    "        \n",
    "    # Possibly three neighborhoods, but could be in \n",
    "    # any of the three input fields\n",
    "    neighborhoods = []\n",
    "    if (n1):\n",
    "        neighborhoods.append(n1)\n",
    "    if (n2):\n",
    "        neighborhoods.append(n2)\n",
    "    if (n3):\n",
    "        neighborhoods.append(n3)\n",
    "        \n",
    "    # Mayor is a structure with mandatory name\n",
    "    # and optional date elected\n",
    "        \n",
    "    mayor = {\"name\": mayor_name}\n",
    "    if year_elected:\n",
    "        mayor[\"year_elected\"] = int(year_elected) if year_elected else None\n",
    "    \n",
    "    city = {\"id\": id, \n",
    "            \"country_code\": country_code,\n",
    "            \"name\": name, \n",
    "            \"district\": district,\n",
    "            \"neighborhoods\": neighborhoods,\n",
    "            \"mayor\": mayor }\n",
    "        \n",
    "    return city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'country_code': 'AFG', 'name': 'Kabul', 'district': 'Kabol', 'neighborhoods': ['Kabul North', 'Kabul Heights'], 'mayor': {'name': 'Muhammad Yunus Nawandish', 'year_elected': 2010}}, {'id': 2, 'country_code': 'AFG', 'name': 'Qandahar', 'district': 'Qandahar', 'neighborhoods': ['Qandahar East', 'Qandahar Heights'], 'mayor': {'name': 'Muhammad Nasim Naseem', 'year_elected': 2011}}, {'id': 5, 'country_code': 'NLD', 'name': 'Amsterdam', 'district': 'Noord-Holland', 'neighborhoods': ['Amsterdam Heights', 'Red Light District', 'New Amsterdam'], 'mayor': {'name': 'Femke Halsema', 'year_elected': 2018}}, {'id': 6, 'country_code': 'NLD', 'name': 'Rotterdam', 'district': '', 'neighborhoods': [], 'mayor': {'name': 'Ahmed Aboutaleb'}}, {'id': 7, 'country_code': 'NLD', 'name': 'Haag', 'district': 'Zuid-Holland', 'neighborhoods': ['Haag Heights', 'Haag Downtown', 'Haag Uptown'], 'mayor': {'name': 'Johannes Remkes', 'year_elected': 2019}}, {'id': 100, 'country_code': 'USA', 'name': 'Seattle', 'district': 'Washington', 'neighborhoods': ['Seattle Heights', 'Ballard', 'Queen Anne'], 'mayor': {'name': 'Jenny Durkan'}}]\n"
     ]
    }
   ],
   "source": [
    "#  How does this related to MapReduce / HDFS?\n",
    "json_cities = read_cities()\n",
    "print(json_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now view the Avro schema for this record type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\": \"record\", \"name\": \"City\", \"fields\": [{\"type\": \"int\", \"name\": \"id\"}, {\"type\": \"string\", \"name\": \"name\"}, {\"type\": {\"type\": \"enum\", \"name\": \"country_code\", \"symbols\": [\"AFG\", \"NLD\", \"USA\"]}, \"name\": \"country_code\"}, {\"type\": [\"string\", \"null\"], \"name\": \"district\"}, {\"type\": {\"type\": \"array\", \"items\": \"string\"}, \"name\": \"neighborhoods\"}, {\"type\": {\"type\": \"record\", \"name\": \"mayor_data\", \"fields\": [{\"type\": \"string\", \"name\": \"name\"}, {\"type\": [\"int\", \"null\"], \"name\": \"year_elected\"}]}, \"name\": \"mayor\"}]}\n"
     ]
    }
   ],
   "source": [
    "import avro.schema\n",
    "\n",
    "# First just parse the schema to see if the declaration is OK syntax\n",
    "schema = avro.schema.Parse(open(\"city.avsc\", \"rb\").read())\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already converted the data to JSON -- now we can write an Avro file with the same data\n",
    "\n",
    "json_cities = read_cities()\n",
    "schema = avro.schema.Parse(open(\"city.avsc\", \"rb\").read())\n",
    "with DataFileWriter(open(\"cities.avro\", \"wb\"), DatumWriter(), schema) as writer:\n",
    "    for record in json_cities:\n",
    "        writer.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ??  What happens if the data doesn't conform to the schema??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kabul, AFG, Muhammad Yunus Nawandish, 2\n",
      "Qandahar, AFG, Muhammad Nasim Naseem, 2\n",
      "Amsterdam, NLD, Femke Halsema, 3\n",
      "Rotterdam, NLD, Ahmed Aboutaleb, 0\n",
      "Haag, NLD, Johannes Remkes, 3\n",
      "Seattle, USA, Jenny Durkan, 3\n"
     ]
    }
   ],
   "source": [
    "# Here's a little \"application\" that processes the Avro file. Simpler, \n",
    "# no splitting no parsing.\n",
    "\n",
    "with DataFileReader(open(\"cities.avro\", \"rb\"), DatumReader()) as reader:\n",
    "    for city in reader:\n",
    "        print(city['name'] + \", \" + city['country_code'] + \", \" + city['mayor']['name'] + \", \" + str(len(city['neighborhoods'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to MapReduce\n",
    "\n",
    "Remember average population per city grouped by country code.  Here is the mapper and reducer.\n",
    "\n",
    "```\n",
    "#!/usr/bin/env python\n",
    "\"\"\"mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "import string\n",
    "\n",
    "# Input records look like this:\n",
    "#   1,Kabul,AFG,Kabol,1780000\n",
    "# The third field is the country code, the fifth field is the population.\n",
    "# We emit (code, population)\n",
    "#\n",
    "# Notice unlike word count, we are no emitting one record per word;\n",
    "# we are just emitting one record per line. So the inner for loop goes away\n",
    "#\n",
    "\n",
    "for line in sys.stdin:\n",
    "    fields = line.strip().split(\",\")\n",
    "    country_code = fields[2]\n",
    "    population = fields[4]\n",
    "    print '%s\\t%s' % (country_code, population)\n",
    "\n",
    "#########################################################\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "# Input is tab-delimited tuples of the form (code, population)\n",
    "# Taking the average population per code is exactly like average\n",
    "# word length per word category\n",
    "\n",
    "current_code = None\n",
    "current_sum = 0\n",
    "current_count = 0\n",
    "code = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    code, pop = line.split('\\t', 1)\n",
    "\n",
    "    if current_code == code:\n",
    "        current_sum += float(pop)\n",
    "        current_count += 1\n",
    "    else:\n",
    "        if current_code:\n",
    "            print '%s\\t%f' % (current_code, current_sum/current_count)\n",
    "        current_code = code\n",
    "        current_sum = float(pop)\n",
    "        current_count = 1\n",
    "\n",
    "if current_code == code:\n",
    "    print '%s\\t%f' % (current_code, current_sum / current_count)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the mapper and reducer change when we switch to reading from Avro rather than text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Changes\n",
    "\n",
    "The schema changes when \n",
    "1. We start buying data from a new provider that supplies different records\n",
    "2. Upstream calculation starts supplying different information\n",
    "\n",
    "In that case\n",
    "* The \"writer\" of the Avro data changes from v1 to v2\n",
    "* Do all of the \"readers\" of the Avro data have to adopt v2, or if they want, can they continue to process the data using v1 schema?\n",
    "\n",
    "This makes a huge difference:  suppose you have *many* readers company-wide, only some of them care about the v2 data.\n",
    "* Does the whole company need to simultaneously switch to v2?\n",
    "* If so, there is so much pain to be had!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema Change Example\n",
    "\n",
    "Our data v2 has the following changes\n",
    "* A new int attribute **area**\n",
    "* Demote the **id** attribute from **long** to **int**\n",
    "* Remove the mistaken country code \"XYZ\"\n",
    "\n",
    "Can our old application still process data written with the new schema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DataFileReader(open(\"cities.avro\", \"rb\"), DatumReader()) as reader:\n",
    "    for city in reader:\n",
    "        print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First let's write some v2 data\n",
    "new_cities = [\n",
    " {'id': 9001, 'name': 'Portland', 'area': 145, 'country_code': 'USA', \n",
    "  'neighborhoods': ['Portland Heights'], 'mayor': {'name': 'Ted Wheeler'}},   \n",
    "  {'id': 9002, 'name': 'Vancouver', 'country_code': 'CAN', 'area': 44,\n",
    "   'neighborhoods': [], \n",
    "   'mayor': {'name': 'Kennedy Stuart', 'year_elected': 2018}}\n",
    "]\n",
    "\n",
    "schema = avro.schema.Parse(open(\"cityv2.avsc\", \"rb\").read())\n",
    "\n",
    "with DataFileWriter(open(\"new_cities.avro\", \"wb\"), DatumWriter(), schema) as writer:\n",
    "    for record in new_cities:\n",
    "        writer.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portland, USA, Ted Wheeler, 1\n"
     ]
    },
    {
     "ename": "SchemaResolutionException",
     "evalue": "Symbol CAN not present in Reader's Schema\nWriter's Schema: {\n  \"type\": \"enum\",\n  \"default\": \"XXX\",\n  \"name\": \"country_code\",\n  \"symbols\": [\n    \"AFG\",\n    \"NLD\",\n    \"USA\",\n    \"CAN\"\n  ]\n}\nReader's Schema: {\n  \"type\": \"enum\",\n  \"default\": \"XXX\",\n  \"name\": \"country_code\",\n  \"symbols\": [\n    \"AFG\",\n    \"NLD\",\n    \"USA\"\n  ]\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSchemaResolutionException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-a512a123425c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mDataFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"new_cities.avro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatumReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", \"\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mcity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country_code'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mayor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'neighborhoods'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\avro\\datafile.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_block_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m     \u001b[0mdatum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatum_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatum_decoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_block_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdatum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\avro\\io.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, decoder)\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader_schema\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader_schema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\avro\\io.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(self, writer_schema, reader_schema, decoder)\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_union\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'request'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m       \u001b[0mfail_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Cannot read unknown schema type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\avro\\io.py\u001b[0m in \u001b[0;36mread_record\u001b[1;34m(self, writer_schema, reader_schema, decoder)\u001b[0m\n\u001b[0;32m    732\u001b[0m       \u001b[0mreaders_field\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreaders_fields_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mreaders_field\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m         \u001b[0mfield_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreaders_field\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    735\u001b[0m         \u001b[0mread_record\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfield_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\avro\\io.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(self, writer_schema, reader_schema, decoder)\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_fixed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'enum'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'array'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\avro\\io.py\u001b[0m in \u001b[0;36mread_enum\u001b[1;34m(self, writer_schema, reader_schema, decoder)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mread_symbol\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[0mfail_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Symbol %s not present in Reader's Schema\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mread_symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mSchemaResolutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfail_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mread_symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSchemaResolutionException\u001b[0m: Symbol CAN not present in Reader's Schema\nWriter's Schema: {\n  \"type\": \"enum\",\n  \"default\": \"XXX\",\n  \"name\": \"country_code\",\n  \"symbols\": [\n    \"AFG\",\n    \"NLD\",\n    \"USA\",\n    \"CAN\"\n  ]\n}\nReader's Schema: {\n  \"type\": \"enum\",\n  \"default\": \"XXX\",\n  \"name\": \"country_code\",\n  \"symbols\": [\n    \"AFG\",\n    \"NLD\",\n    \"USA\"\n  ]\n}"
     ]
    }
   ],
   "source": [
    "## This is the case of an v1 application \n",
    "## -- that knows only about the v1 schema --\n",
    "## processing data written with the v2 schema\n",
    "\n",
    "reader_schema = avro.schema.Parse(open(\"city.avsc\", \"rb\").read()) \n",
    "writer_schema = avro.schema.Parse(open(\"cityv2.avsc\", \"rb\").read())\n",
    "\n",
    "with DataFileReader(open(\"new_cities.avro\", \"rb\"), DatumReader(writer_schema, reader_schema)) as reader:\n",
    "    for city in reader:\n",
    "        print(city['name'] + \", \" +  city['country_code'] + \", \" + city['mayor']['name'] + \", \" + str(len(city['neighborhoods'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
